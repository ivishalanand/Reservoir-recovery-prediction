# -*- coding: utf-8 -*-
"""Reservoir

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b-L5lqtWvJ-W2CMdUBlMi3kC52dnTW7J
"""

import pandas as pd
import numpy as np
X=pd.read_csv("okay.csv")
import random 
  
random.seed(42)

X.head()

np.random.seed(42)
X.describe()
X.info()

X.isna().any()

y=pd.DataFrame(X.REC)
X=X.drop(["REC"],axis=1)

X['k/uob'] =pd.to_numeric(X['k/uob'],errors='coerce')

X.isna().any()
X["k/uob"].fillna(X["k/uob"].mean(), inplace=True)
X.isna().any()

X_categorical=pd.get_dummies(X.Type)
X_numeric=X.drop(["Type"],axis=1)

X.info()

#normalising the data
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
X_numeric = pd.DataFrame(scaler.fit_transform(X_numeric), index=X_numeric.index, columns=X_numeric.columns)

#Anomaly detection
import matplotlib.pyplot as plt
import seaborn as sns

#removing anomaly
from sklearn.ensemble import IsolationForest

clf = IsolationForest(contamination=0.05, random_state=42)
clf.fit(X_numeric)
anomaly=clf.predict(X_numeric)
X_numeric['anomaly']=anomaly
X_categorical['ANOMALY']=anomaly
y['anomaly']=anomaly
X_numeric=X_numeric[X_numeric.anomaly>0]
X_categorical=X_categorical[X_categorical.ANOMALY>0]
y=y[y.anomaly>0]

import pandas as pd
import numpy as np
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2

X=pd.concat([X_numeric,X_categorical],axis=1)
X.isna().any()
X=X.drop(['anomaly','ANOMALY'],axis=1)
y=y.drop(['anomaly'],axis=1)

#normalised X
X.head()

#feature selection



#apply SelectKBest class to extract top 10 best features
from sklearn.ensemble import ExtraTreesClassifier
import matplotlib.pyplot as plt
model = ExtraTreesClassifier()
model.fit(X,y)
print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers

#plot graph of feature importances for better visualization
feat_importances = pd.Series(model.feature_importances_, index=X.columns)

feat_importances.nlargest(10).plot(kind='barh')
plt.show()

selected_features_15=['OOIP','POROSITY','K','Sw','T','Rsb','Pep','k/uob','Bol','Rsa','PI','Boa','Uw','Uoa','API',1,2,3,4]
selected_features_10=['OOIP','POROSITY','K','Sw','T','Rsb','Pep','k/uob','Bol','Rsa',1,2,3,4]

#heatmap

import seaborn as sns
corrmat = X.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(20,20))
#plot heat map
g=sns.heatmap(X[top_corr_features].corr(),annot=True,cmap="RdYlGn")
# =============================================================================

#15 features

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X[selected_features_15],y,test_size=.2)

#PCA
random.seed(42) 
a=[]
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
for n in range(2,19):
    random.seed(42) 

    X_train, X_test, Y_train, Y_test = train_test_split(X[selected_features_15],y,test_size=.2)
    
    from sklearn.decomposition import PCA
    pca = PCA(n_components=n)
    X_train = pca.fit_transform(X_train) 
    X_test = pca.transform(X_test) 
    explained_variance = pca.explained_variance_ratio_
    
    classifier=LinearRegression()
    classifier.fit(X_train,Y_train)
    Y_pred = classifier.predict(X_test) 
    
    a.append( mean_squared_error(Y_pred,Y_test))
#plotting mse wrt pca dimention 
    plt.plot(a)
#best dimention is 13 dimention using pca

    X=X.reset_index().drop(['index'],axis=1)
    y=y.reset_index().drop(['index'],axis=1)

print(a)

# Linear Regression model
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, median_absolute_error  
from sklearn.linear_model import LinearRegression 
from math import sqrt
clf_lr = LinearRegression()
clf_lr.fit(X_train,Y_train)
Y_pred_lr = clf_lr.predict(X_test)
print(mean_squared_error(Y_pred_lr,Y_test))
print(mean_absolute_error(Y_pred_lr,Y_test))
print(sqrt(mean_squared_error(Y_pred_lr,Y_test)))
print(r2_score(Y_pred_lr,Y_test))
print(median_absolute_error (Y_pred_lr,Y_test))

#Advanced analysis of data and modelling

a=X
a['REC']=y

a.to_csv("processed.csv")

a.head()

a.describe()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt
import warnings
import xgboost as xgb
import lightgbm as lgb
from scipy.stats import skew
from scipy import stats
from scipy.stats.stats import pearsonr
from scipy.stats import norm
from collections import Counter
from sklearn.linear_model import LinearRegression,LassoCV, Ridge, LassoLarsCV,ElasticNetCV
from sklearn.model_selection import GridSearchCV, cross_val_score, learning_curve
from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler, Normalizer, RobustScaler
warnings.filterwarnings('ignore')
sns.set(style='white', context='notebook', palette='deep')
# %config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook
# %matplotlib inline

df = pd.read_csv("processed.csv")
df2=df.sample(frac=1)
#df2.drop("Unnamed: 0",axis=1,inplace=True)
train=df2.iloc[:301,:]
test=df2.iloc[301:,:]

train['1'].unique()

# Check the numbers of samples and features
print("The train data size before dropping Unnamed: 0 feature is : {} ".format(train.shape))
print("The test data size before dropping Unnamed: 0 feature is : {} ".format(test.shape))

# Save the 'Unnamed: 0' column
train_ID = train['Unnamed: 0']
test_ID = test['Unnamed: 0']

# Now drop the 'Unnamed: 0' column since it's unnecessary for the prediction process.
train.drop("Unnamed: 0", axis = 1, inplace = True)
test.drop("Unnamed: 0", axis = 1, inplace = True)

# Check data size after dropping the 'Id' variable
print("\nThe train data size after dropping Id feature is : {} ".format(train.shape)) 
print("The test data size after dropping Id feature is : {} ".format(test.shape))

train.head()
test.head()

# Getting Description
train['REC'].describe()

# Plot Histogram
sns.distplot(train['REC'] , fit=norm);

# Plot Histogram
sns.distplot(train['REC'] , fit=norm);

# Get the fitted parameters used by the function
(mu, sigma) = norm.fit(train['REC'])
print( '\n mu = {:.2f} and sigma = {:.2f}\n'.format(mu, sigma))
plt.legend(['Normal dist. ($\mu=$ {:.2f} and $\sigma=$ {:.2f} )'.format(mu, sigma)],
            loc='best')
plt.ylabel('Frequency')
plt.title('REC distribution')

fig = plt.figure()
res = stats.probplot(train['REC'], plot=plt)
plt.show()

print("Skewness: %f" % train['REC'].skew())
print("Kurtosis: %f" % train['REC'].kurt())

#Multivariate Analysis
train.select_dtypes(include=['object']).columns
train.select_dtypes(include=['int64','float64']).columns

cat = len(train.select_dtypes(include=['object']).columns)
num = len(train.select_dtypes(include=['int64','float64']).columns)
print('Total Features: ', cat, 'categorical', '+',
      num, 'numerical', '=', cat+num, 'features')

# Correlation Matrix Heatmap
corrmat = train.corr()
f, ax = plt.subplots(figsize=(12, 9))
sns.heatmap(corrmat, vmax=.8, square=True);

k = 15 #number of variables for heatmap
cols = corrmat.nlargest(k, 'REC')['REC'].index
cm = np.corrcoef(train[cols].values.T)
sns.set(font_scale=1.25)
hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)
plt.show()

most_corr = pd.DataFrame(cols)
most_corr.columns = ['Most Correlated Features']
most_corr

#outlier removal

#OOIP vs REC
sns.jointplot(x=train['OOIP'], y=train['REC'], kind='reg')
#removing the outliers manually
train = train.drop(train[(train['OOIP']>2) & (train['REC']>1250)].index).reset_index(drop=True)
sns.jointplot(x=train['OOIP'], y=train['REC'], kind='reg')

#K vs REC
sns.jointplot(x=train['K'], y=train['REC'], kind='reg')
#removing the outlier
train = train.drop(train[(train['K']>15) & (train['REC']>0)].index).reset_index(drop=True)
sns.jointplot(x=train['K'], y=train['REC'], kind='reg')

#k/uob vs REC
sns.jointplot(x=train['k/uob'], y=train['REC'], kind='reg')
#removing outliers
train = train.drop(train[(train['k/uob']>10) & (train['REC']>0)].index).reset_index(drop=True)
sns.jointplot(x=train['k/uob'], y=train['REC'], kind='reg')

#pep vs REC
sns.jointplot(x=train['Pep'], y=train['REC'], kind='reg')

#T vs REC
sns.jointplot(x=train['T'], y=train['REC'], kind='reg')
#removing outliers
train = train.drop(train[(train['T']>10) & (train['REC']>0)].index).reset_index(drop=True)
sns.jointplot(x=train['k/uob'], y=train['REC'], kind='reg')

#RSA vs REC
sns.jointplot(x=train['Rsa'], y=train['REC'], kind='reg')

#Uoi vs REC
sns.jointplot(x=train['Uoi'], y=train['REC'], kind='reg')

#Uoa vs REC
sns.jointplot(x=train['Uoa'], y=train['REC'], kind='reg')

#Bp vs REC
sns.jointplot(x=train['Bp'], y=train['REC'], kind='reg')
train = train.drop(train[(train['Bp']>10) & (train['REC']>0)].index).reset_index(drop=True)
sns.jointplot(x=train['Bp'], y=train['REC'], kind='reg')

#removing outliers
train = train.drop(train[(train['Bp']>15) & (train['REC']>0)].index).reset_index(drop=True)
sns.jointplot(x=train['Bp'], y=train['REC'], kind='reg')

#Ubp vs REC
sns.jointplot(x=train['Ubp'], y=train['REC'], kind='reg')

#h vs REC
sns.jointplot(x=train['h'], y=train['REC'], kind='reg')
#removing outliers
train = train.drop(train[(train['h']>10) & (train['REC']>0)].index).reset_index(drop=True)
sns.jointplot(x=train['h'], y=train['REC'], kind='reg')

#Porosity vs REC
sns.jointplot(x=train['POROSITY'], y=train['REC'], kind='reg')
#removing outliers

#Boa vs REC
sns.jointplot(x=train['Boa'], y=train['REC'], kind='reg')

# Combining Datasets
ntrain = train.shape[0]
ntest = test.shape[0]
y_train = train.REC.values
all_data = pd.concat((train, test)).reset_index(drop=True)
all_data.drop(['REC'], axis=1, inplace=True)
print("Train data size is : {}".format(train.shape))
print("Test data size is : {}".format(test.shape))
print("Combined dataset size is : {}".format(all_data.shape))

y_train = train.REC.values

print("Skewness: %f" % train['REC'].skew())
print("Kurtosis: %f" % train['REC'].kurt())

numeric_feats = all_data.dtypes[all_data.dtypes != "object"].index

train = all_data[:ntrain]
test = all_data[ntrain:]

train.head()

#Modelling and predictions
from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC
from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor
from sklearn.kernel_ridge import KernelRidge
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import RobustScaler
from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone
from sklearn.model_selection import KFold, cross_val_score, train_test_split
from sklearn.metrics import mean_squared_error
import xgboost as xgb
import lightgbm as lgb

# Linear Regression model
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, median_absolute_error  
from sklearn.linear_model import LinearRegression 
from math import sqrt
clf_lr = LinearRegression()
clf_lr.fit(X_train,Y_train)
y_pred_lr = clf_lr.predict(X_test)
print("\nmean squared error {:.4f}\n".format(mean_squared_error(y_pred_lr,Y_test)))
print("\nmean absolute error {:.4f}\n".format(mean_absolute_error(y_pred_lr,Y_test)))
print("\nroot mean squared error {:.4f}\n".format(sqrt(mean_squared_error(y_pred_lr,Y_test))))
print("\nr2 squscore {:.4f}\n".format(r2_score(y_pred_lr,Y_test)))
print("\nmedian absolute error {:.4f}\n".format(median_absolute_error (y_pred_lr,Y_test)))

from sklearn.svm import SVR
clf = SVR(kernel='rbf', C=1e3, gamma=0.1)
clf.fit(X_train,Y_train)
y_pred_lr = clf.predict(X_test)
print("\nmean squared error {:.4f}\n".format(mean_squared_error(y_pred_lr,Y_test)))
print("\nmean absolute error {:.4f}\n".format(mean_absolute_error(y_pred_lr,Y_test)))
print("\nroot mean squared error {:.4f}\n".format(sqrt(mean_squared_error(y_pred_lr,Y_test))))
print("\nr2 squscore {:.4f}\n".format(r2_score(y_pred_lr,Y_test)))
print("\nmedian absolute error {:.4f}\n".format(median_absolute_error (y_pred_lr,Y_test)))

# Random Forest Regressor
from sklearn.ensemble import RandomForestRegressor
clf = RandomForestRegressor(n_estimators=100)
clf.fit(X_train,Y_train)
y_pred_lr = clf.predict(X_test)
print("\nmean squared error {:.4f}\n".format(mean_squared_error(y_pred_lr,Y_test)))
print("\nmean absolute error {:.4f}\n".format(mean_absolute_error(y_pred_lr,Y_test)))
print("\nroot mean squared error {:.4f}\n".format(sqrt(mean_squared_error(y_pred_lr,Y_test))))
print("\nr2 squscore {:.4f}\n".format(r2_score(y_pred_lr,Y_test)))
print("\nmedian absolute error {:.4f}\n".format(median_absolute_error (y_pred_lr,Y_test)))

from sklearn.ensemble import GradientBoostingRegressor
clf = GradientBoostingRegressor(n_estimators=200)
clf.fit(X_train,Y_train)
y_pred_lr = clf.predict(X_test)
print("\nmean squared error {:.4f}\n".format(mean_squared_error(y_pred_lr,Y_test)))
print("\nmean absolute error {:.4f}\n".format(mean_absolute_error(y_pred_lr,Y_test)))
print("\nroot mean squared error {:.4f}\n".format(sqrt(mean_squared_error(y_pred_lr,Y_test))))
print("\nr2 squscore {:.4f}\n".format(r2_score(y_pred_lr,Y_test)))
print("\nmedian absolute error {:.4f}\n".format(median_absolute_error (y_pred_lr,Y_test)))

clf = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))
clf.fit(X_train,Y_train)
y_pred_lr = clf.predict(X_test)
print("\nmean squared error {:.4f}\n".format(mean_squared_error(y_pred_lr,Y_test)))
print("\nmean absolute error {:.4f}\n".format(mean_absolute_error(y_pred_lr,Y_test)))
print("\nroot mean squared error {:.4f}\n".format(sqrt(mean_squared_error(y_pred_lr,Y_test))))
print("\nr2 squscore {:.4f}\n".format(r2_score(y_pred_lr,Y_test)))
print("\nmedian absolute error {:.4f}\n".format(median_absolute_error (y_pred_lr,Y_test)))

clf = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))
clf.fit(X_train,Y_train)
y_pred_lr = clf.predict(X_test)
print("\nmean squared error {:.4f}\n".format(mean_squared_error(y_pred_lr,Y_test)))
print("\nmean absolute error {:.4f}\n".format(mean_absolute_error(y_pred_lr,Y_test)))
print("\nroot mean squared error {:.4f}\n".format(sqrt(mean_squared_error(y_pred_lr,Y_test))))
print("\nr2 squscore {:.4f}\n".format(r2_score(y_pred_lr,Y_test)))
print("\nmedian absolute error {:.4f}\n".format(median_absolute_error (y_pred_lr,Y_test)))

clf = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)
clf.fit(X_train,Y_train)
y_pred_lr = clf.predict(X_test)
print("\nmean squared error {:.4f}\n".format(mean_squared_error(y_pred_lr,Y_test)))
print("\nmean absolute error {:.4f}\n".format(mean_absolute_error(y_pred_lr,Y_test)))
print("\nroot mean squared error {:.4f}\n".format(sqrt(mean_squared_error(y_pred_lr,Y_test))))
print("\nr2 squscore {:.4f}\n".format(r2_score(y_pred_lr,Y_test)))
print("\nmedian absolute error {:.4f}\n".format(median_absolute_error (y_pred_lr,Y_test)))

clf = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,
                                   max_depth=4, max_features='sqrt',
                                   min_samples_leaf=15, min_samples_split=10, 
                                   loss='huber', random_state =5)
clf.fit(X_train,Y_train)
y_pred_lr = clf.predict(X_test)
print("\nmean squared error {:.4f}\n".format(mean_squared_error(y_pred_lr,Y_test)))
print("\nmean absolute error {:.4f}\n".format(mean_absolute_error(y_pred_lr,Y_test)))
print("\nroot mean squared error {:.4f}\n".format(sqrt(mean_squared_error(y_pred_lr,Y_test))))
print("\nr2 squscore {:.4f}\n".format(r2_score(y_pred_lr,Y_test)))
print("\nmedian absolute error {:.4f}\n".format(median_absolute_error (y_pred_lr,Y_test)))

clf = xgb.XGBRegressor(colsample_bytree=0.2, gamma=0.0, 
                             learning_rate=0.05, max_depth=6, 
                             min_child_weight=1.5, n_estimators=7200,
                             reg_alpha=0.9, reg_lambda=0.6,
                             subsample=0.2,seed=42, silent=1,
                             random_state =7)
clf.fit(X_train,Y_train)
y_pred_lr = clf.predict(X_test)
print("\nmean squared error {:.4f}\n".format(mean_squared_error(y_pred_lr,Y_test)))
print("\nmean absolute error {:.4f}\n".format(mean_absolute_error(y_pred_lr,Y_test)))
print("\nroot mean squared error {:.4f}\n".format(sqrt(mean_squared_error(y_pred_lr,Y_test))))
print("\nr2 squscore {:.4f}\n".format(r2_score(y_pred_lr,Y_test)))
print("\nmedian absolute error {:.4f}\n".format(median_absolute_error (y_pred_lr,Y_test)))

clf = lgb.LGBMRegressor(objective='regression',num_leaves=5,
                              learning_rate=0.05, n_estimators=720,
                              max_bin = 55, bagging_fraction = 0.8,
                              bagging_freq = 5, feature_fraction = 0.2319,
                              feature_fraction_seed=9, bagging_seed=9,
                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)
clf.fit(X_train,Y_train)
y_pred_lr = clf.predict(X_test)
print("\nmean squared error {:.4f}\n".format(mean_squared_error(y_pred_lr,Y_test)))
print("\nmean absolute error {:.4f}\n".format(mean_absolute_error(y_pred_lr,Y_test)))
print("\nroot mean squared error {:.4f}\n".format(sqrt(mean_squared_error(y_pred_lr,Y_test))))
print("\nr2 squscore {:.4f}\n".format(r2_score(y_pred_lr,Y_test)))
print("\nmedian absolute error {:.4f}\n".format(median_absolute_error (y_pred_lr,Y_test)))

